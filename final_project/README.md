# AI Analytics Assistant

> A production-ready Slack bot that enables business users to query BigQuery data warehouses using natural language, powered by LangGraph orchestration and GPT-4.

## ğŸ¯ What It Does

Transforms questions like *"What was our revenue last month?"* into optimized BigQuery SQL queries, executes them safely, and returns formatted results in Slack.

### Key Features

- **Natural Language Interface** - No SQL knowledge required
- **Smart Context** - Uses RAG to understand your data schema and business logic
- **Safety First** - Automatic cost estimation, query validation, and execution limits
- **Intelligent Caching** - Reduces costs by caching results based on query patterns
- **Session Awareness** - Maintains context across multiple questions

## ğŸ—ï¸ Architecture Overview

```
User â†’ Slack Bot â†’ Redis Queue â†’ Workers â†’ BigQuery
         â†‘                           â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€ Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

| Component | Role | Technology |
|-----------|------|------------|
| **Slack Bot** | User interface, message routing | Python, Slack Bolt |
| **Workers** | Query processing, SQL generation | LangGraph, OpenAI |
| **Queue** | Task distribution, decoupling | Redis |
| **Vector DB** | Schema and documentation search | Qdrant |
| **Data Warehouse** | Query execution | Google BigQuery |

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Google Cloud Project with BigQuery
- OpenAI API key
- Slack workspace admin access

### Installation

```bash
# Clone and setup
git clone https://github.com/your-org/ai-analytics-assistant.git
cd ai-analytics-assistant
cp .env.example .env

# Configure credentials in .env
# - Slack tokens (SLACK_BOT_TOKEN, SLACK_APP_TOKEN)
# - OpenAI key (OPENAI_API_KEY)
# - BigQuery project (BQ_SOURCE_PROJECT)

# Start services
docker-compose up -d

# Verify health
make status
```

### Slack Setup

1. Create app at [api.slack.com/apps](https://api.slack.com/apps) using the manifest in `docs/slack-manifest.yaml`
2. Enable Socket Mode and generate app token
3. Install to workspace
4. Invite bot to channels: `/invite @AI Analytics Assistant`

## ğŸ’¬ Usage

### In Slack

- **Direct Message**: `what's our MRR?`
- **Mention**: `@AI Analytics Assistant show top 10 customers`
- **Slash Command**: `/ask calculate churn rate for Q4`

### Query Flow

1. Bot acknowledges: *"ğŸ” Analyzing your request..."*
2. Worker processes in background
3. Returns preview with cost estimate
4. Executes after confirmation (if expensive)
5. Delivers formatted results

## ğŸ›¡ï¸ Safety Features

- **Read-only** queries (SELECT only)
- **Cost limits** ($5 default per query)
- **Data limits** (20GB scan maximum)
- **Partition enforcement** for large tables
- **Rate limiting** per user/workspace
- **Channel restrictions** for sensitive data

## ğŸ“ Project Structure

```
ai-analytics-assistant/
â”œâ”€â”€ slack_bot/          # Slack interface (Producer)
â”œâ”€â”€ workers/            # Query processing (Consumers)
â”‚   â”œâ”€â”€ graphs/        # LangGraph workflows
â”‚   â”œâ”€â”€ tools/         # BigQuery, RAG integrations
â”‚   â””â”€â”€ utils/         # Caching, sessions
â”œâ”€â”€ docs/              # Documentation
â”œâ”€â”€ docker-compose.yml # Service orchestration
â””â”€â”€ .env.example       # Configuration template
```

## ğŸ”„ How It Works

### LangGraph Orchestration

The system uses a state machine approach to process queries:

```
Initialize â†’ Gather Context â†’ Generate SQL â†’ Validate â†’ Execute â†’ Format Results
                    â†“              â†“            â†“         â†“
                  [RAG]         [GPT-4o-mini]    [Dry Run]  [BigQuery]
```

### Intelligent Caching

- **Historical data** â†’ Cached permanently
- **Aggregations** â†’ Cached for 1 hour  
- **Real-time data** â†’ Never cached
- **Schema queries** â†’ Cached for 24 hours

## ğŸ“Š Configuration

Key settings in `.env`:

```bash
# Model Selection
OPENAI_MODEL=gpt-4o-mini  # or gpt-4-turbo for better quality

# Safety Limits  
BQ_MAX_BYTES_BILLED=20000000000  # 20GB
MAX_QUERY_COST=5.0                # $5

# Rate Limiting
RATE_LIMIT_PER_MIN=10
CONCURRENT_LIMIT=5
```

See [.env.example](.env.example) for all options.

## ğŸ”§ Operations

### Monitoring

```bash
# View logs
make logs

# Check queue depth
make queue-status

# Health check
curl http://localhost:8080/health
```

### Scaling

```bash
# Scale workers horizontally
docker-compose up --scale worker=1

# Adjust per-worker concurrency
WORKER_CONCURRENCY=2 docker-compose up
```

## ğŸ“š Documentation

- **[Architecture Guide](docs/ARCHITECTURE.md)** - System design and patterns
- **[Setup Guide](docs/SETUP.md)** - Detailed installation instructions
- **[Slack Bot](slack_bot/README.md)** - Bot component details
- **[Workers](workers/README.md)** - Processing engine documentation
- **[LangGraph Workflows](workers/graphs/README.md)** - Orchestration details
- **[Tools](workers/tools/README.md)** - External integrations