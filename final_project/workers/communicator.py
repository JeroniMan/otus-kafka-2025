"""
Slack Communicator for sending updates from workers
"""

import json
import traceback
import re
import base64
from typing import Dict, Any, Optional, List  # –î–û–ë–ê–í–õ–ï–ù–û List
from datetime import datetime
from decimal import Decimal

import structlog
import redis.asyncio as redis
from langchain_openai import ChatOpenAI  # –î–û–ë–ê–í–õ–ï–ù–û –¥–ª—è LLM –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏

from workers.config import settings

logger = structlog.get_logger()


class JSONEncoder(json.JSONEncoder):
    """Custom JSON encoder that handles datetime and other special types"""

    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        elif isinstance(obj, bytes):
            return obj.decode('utf-8', errors='ignore')
        elif hasattr(obj, '__dict__'):
            return str(obj)
        return super().default(obj)


class SlackCommunicator:
    """Handles communication from workers to Slack bot via Redis Pub/Sub"""

    def __init__(self, redis_client: redis.Redis):
        self.redis_client = redis_client
        self.pubsub_channel = settings.pubsub_channel

        # –î–û–ë–ê–í–õ–ï–ù–û: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
        self.interpreter_llm = ChatOpenAI(
            model=settings.openai_model,
            temperature=0.3  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
        )

    async def send_progress(self, task: Dict[str, Any], message: str):
        """Send progress update to Slack (alias for send_status_update)"""
        await self.send_status_update(task, message)

    async def send_status_update(self, task: Dict, message: str, blocks: Optional[list] = None):
        """Send status update to Slack"""

        try:
            update = {
                "type": "status_update",
                "task_id": task["id"],
                "slack_context": task.get("slack_context", {}),
                "message": message,
                "blocks": blocks,
                "timestamp": datetime.utcnow().isoformat()
            }

            await self._publish(update)
            logger.debug("sent_status_update", task_id=task["id"], message=message)

        except Exception as e:
            logger.error("failed_to_send_status_update",
                         error=str(e),
                         task_id=task.get("id"),
                         traceback=traceback.format_exc())

    async def send_result(self, task: Dict[str, Any], result: Dict[str, Any]):
        """Send final result to Slack (alias for send_query_result)"""
        await self.send_query_result(task, result)

    async def send_query_result(self, task: Dict, result: Dict[str, Any]):
        """Send query execution result to Slack bot for posting"""

        try:
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ö–æ–¥—è—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            logger.debug("DEBUG send_query_result input",
                        task_id=task.get("id"),
                        result_keys=list(result.keys()) if result else None,
                        has_html_report=bool(result.get("html_report")),
                        has_results=bool(result.get("results")),
                        total_rows=result.get("total_rows"),
                        rows_count=result.get("rows_count"),
                        results_len=len(result.get("results", [])) if result else 0)

            # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è JSON
            clean_result = self._clean_for_json(result)

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –±–ª–æ–∫–∏ –¥–ª—è Slack
            if result.get("report"):
                blocks = self._format_result_blocks(result["report"])
            else:
                # Fallback –µ—Å–ª–∏ –Ω–µ—Ç –æ—Ç—á–µ—Ç–∞
                simple_report = {
                    "summary": f"Query completed successfully. Found {clean_result.get('total_rows', 0)} rows.",
                    "preview": clean_result.get("preview", clean_result.get("results", []))[:10],
                    "results": clean_result.get("results", []),
                    "sql": clean_result.get("sql", ""),
                    "rows_count": clean_result.get("total_rows", 0),
                    "bytes_processed_gb": clean_result.get("bytes_processed", 0) / (1024 ** 3) if clean_result.get(
                        "bytes_processed") else 0,
                    "table_link": clean_result.get("table_link"),
                    "execution_time_ms": clean_result.get("execution_time_ms", 0),
                    "estimated_cost": clean_result.get("estimated_cost", 0),
                    "cache_hit": clean_result.get("cache_hit", False)
                }
                blocks = self._format_result_blocks(simple_report)

            # –ò–ó–ú–ï–ù–ï–ù–û: –ö–æ–¥–∏—Ä—É–µ–º HTML –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —á–µ—Ä–µ–∑ Redis
            html_report_encoded = None
            if result.get("html_report"):
                try:
                    # –ö–æ–¥–∏—Ä—É–µ–º HTML –≤ base64 –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ —á–µ—Ä–µ–∑ JSON
                    html_bytes = result["html_report"].encode('utf-8')
                    html_report_encoded = base64.b64encode(html_bytes).decode('ascii')
                    logger.debug("html_report_encoded",
                               task_id=task.get("id"),
                               original_size=len(result["html_report"]),
                               encoded_size=len(html_report_encoded))
                except Exception as e:
                    logger.error("html_encoding_failed",
                               task_id=task.get("id"),
                               error=str(e))

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —á–µ—Ä–µ–∑ Redis
            update = {
                "type": "query_result",
                "task_id": task["id"],
                "slack_context": task.get("slack_context", {}),
                "message": self._format_result_message(clean_result),
                "result": clean_result,
                "blocks": blocks,
                "html_report_encoded": html_report_encoded,  # –ò–ó–ú–ï–ù–ï–ù–û: –ü–µ—Ä–µ–¥–∞–µ–º –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π HTML
                "timestamp": datetime.utcnow().isoformat()
            }

            await self._publish(update)

            logger.info("sent_query_result",
                       task_id=task["id"],
                       rows=clean_result.get("rows_count", clean_result.get("total_rows", 0)),
                       has_html_report=bool(html_report_encoded))

        except Exception as e:
            logger.error("failed_to_send_query_result",
                        error=str(e),
                        task_id=task.get("id"),
                        result_keys=list(result.keys()) if result else None,
                        traceback=traceback.format_exc())

            await self.send_error(
                task,
                "Failed to format query results",
                details=str(e)
            )

    # –î–û–ë–ê–í–õ–ï–ù–û: –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è LLM –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
    async def _get_llm_interpretation(
            self,
            question: str,
            sql: str,
            results: List[Dict],
            total_rows: int
    ) -> Optional[str]:
        """
        Get intelligent interpretation of results using LLM
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ LLM –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
            if not self._needs_llm_interpretation(question, sql, results):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                return self._get_simple_interpretation(sql, results, total_rows)

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
            prompt = f"""You are a data analyst assistant. Interpret the query results in a clear, concise way.

User Question: {question}

SQL Query Executed:
{sql}

Query Results (first {len(results)} rows of {total_rows} total):
{self._format_results_for_prompt(results)}

Provide a brief, insightful interpretation of these results that directly answers the user's question.
Focus on:
1. What the data shows
2. Key insights or patterns
3. Business implications if relevant

Keep the interpretation to 2-3 sentences maximum.
Do not repeat the SQL or restate the question.
Be specific with numbers and facts from the results."""

            # –í—ã–∑—ã–≤–∞–µ–º LLM
            response = await self.interpreter_llm.ainvoke(prompt)
            interpretation = response.content if hasattr(response, 'content') else str(response)

            # –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            interpretation = interpretation.strip()

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è Slack
            if len(interpretation) > 500:
                interpretation = interpretation[:497] + "..."

            logger.debug("LLM interpretation generated",
                         question_length=len(question),
                         interpretation_length=len(interpretation))

            return interpretation

        except Exception as e:
            logger.warning("Failed to get LLM interpretation",
                           error=str(e),
                           question=question[:100])
            # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é
            return self._get_simple_interpretation(sql, results, total_rows)

    # –î–û–ë–ê–í–õ–ï–ù–û: –ú–µ—Ç–æ–¥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ LLM
    def _needs_llm_interpretation(
            self,
            question: str,
            sql: str,
            results: List[Dict]
    ) -> bool:
        """
        Determine if LLM interpretation would be valuable
        """
        question_lower = question.lower()
        sql_lower = sql.lower()

        # –ü—Ä–æ—Å—Ç—ã–µ COUNT –∑–∞–ø—Ä–æ—Å—ã –Ω–µ —Ç—Ä–µ–±—É—é—Ç LLM
        if "count(*)" in sql_lower and "group by" not in sql_lower:
            return False

        # –í–æ–ø—Ä–æ—Å—ã —Ç—Ä–µ–±—É—é—â–∏–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
        interpretation_keywords = [
            "why", "what does", "explain", "analyze",
            "compare", "trend", "pattern", "insight",
            "significant", "unusual", "interesting"
        ]
        if any(keyword in question_lower for keyword in interpretation_keywords):
            return True

        # –°–ª–æ–∂–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        if "group by" in sql_lower and len(results) > 1:
            return True

        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if results and len(results[0]) > 3:
            return True

        # –í—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
        if any(op in sql_lower for op in ["avg(", "sum(", "stddev(", "percentile"]):
            return True

        # JOIN –∑–∞–ø—Ä–æ—Å—ã –æ–±—ã—á–Ω–æ —Ç—Ä–µ–±—É—é—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        if "join" in sql_lower:
            return True

        return False

    # –î–û–ë–ê–í–õ–ï–ù–û: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    def _format_results_for_prompt(self, results: List[Dict], max_rows: int = 10) -> str:
        """Format results for LLM prompt"""
        if not results:
            return "No results returned"

        lines = []

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        headers = list(results[0].keys())
        lines.append(" | ".join(headers))
        lines.append("-" * 50)

        # –î–∞–Ω–Ω—ã–µ
        for row in results[:max_rows]:
            values = [str(row.get(h, "")) for h in headers]
            lines.append(" | ".join(values))

        return "\n".join(lines)

    # –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
    def _get_simple_interpretation(
            self,
            sql: str,
            results: List[Dict],
            total_rows: int
    ) -> Optional[str]:
        """
        Simple rule-based interpretation for basic queries
        """
        try:
            sql_lower = sql.lower()

            # –î–ª—è COUNT –∑–∞–ø—Ä–æ—Å–æ–≤
            if "count(*)" in sql_lower or "count(1)" in sql_lower:
                if results and len(results) > 0:
                    first_row = results[0]
                    count_value = None
                    for key, value in first_row.items():
                        if 'count' in key.lower() or key == 'f0_':
                            count_value = value
                            break

                    if count_value is not None:
                        if "information_schema.tables" in sql_lower:
                            if "raw_solana" in sql_lower:
                                return f"The raw_solana dataset contains {count_value} tables."
                            else:
                                return f"Found {count_value} tables in the dataset."
                        else:
                            return f"Count result: {count_value}"

            # –î–ª—è –¥—Ä—É–≥–∏—Ö –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤
            if total_rows == 1 and results:
                return None  # –ù–µ –Ω—É–∂–Ω–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
            elif total_rows > 10:
                return f"Query returned {total_rows} rows. Showing first 10 rows."

            return None

        except Exception as e:
            logger.debug("Simple interpretation failed", error=str(e))
            return None

    async def send_confirmation_request(self, task: Dict, dry_run_result: Dict):
        """Send confirmation request to Slack"""

        try:
            # Generate interaction ID for this confirmation
            interaction_id = f"{task['id']}_confirm"

            # Clean dry run result
            clean_dry_run = self._clean_for_json(dry_run_result)

            # Store session data for later
            await self._store_session(interaction_id, {
                "task": task,
                "dry_run_result": clean_dry_run,
                "sql": clean_dry_run.get("sql", "")
            })

            # Format confirmation blocks
            blocks = self._format_confirmation_blocks(clean_dry_run)

            update = {
                "type": "request_confirmation",
                "task_id": task["id"],
                "slack_context": task.get("slack_context", {}),
                "message": "Query validation complete. Please review and confirm.",
                "dry_run_result": clean_dry_run,
                "blocks": blocks,
                "interaction_id": interaction_id,
                "timestamp": datetime.utcnow().isoformat()
            }

            await self._publish(update)
            logger.info("sent_confirmation_request",
                        task_id=task["id"],
                        bytes_gb=clean_dry_run.get("total_bytes_billed", 0) / (1024 ** 3))

        except Exception as e:
            logger.error("failed_to_send_confirmation",
                         error=str(e),
                         task_id=task.get("id"),
                         traceback=traceback.format_exc())

    async def send_error(self, task: Dict, error: str, details: Optional[str] = None):
        """Send error message to Slack"""

        try:
            # Format error blocks
            blocks = self._format_error_blocks(error, details)

            update = {
                "type": "error",
                "task_id": task["id"],
                "slack_context": task.get("slack_context", {}),
                "message": f"‚ùå Query failed: {error}",
                "error": error,
                "details": details,
                "blocks": blocks,
                "timestamp": datetime.utcnow().isoformat()
            }

            await self._publish(update)
            logger.error("sent_error", task_id=task["id"], error=error)

        except Exception as e:
            logger.error("failed_to_send_error",
                         original_error=error,
                         send_error=str(e),
                         task_id=task.get("id"),
                         traceback=traceback.format_exc())

    async def _publish(self, update: Dict):
        """Publish update to Redis Pub/Sub"""

        try:
            # Use custom encoder for JSON serialization
            message = json.dumps(update, cls=JSONEncoder)
            await self.redis_client.publish(self.pubsub_channel, message)

            logger.debug("published_to_redis",
                         channel=self.pubsub_channel,
                         update_type=update.get("type"),
                         message_size=len(message))

        except TypeError as e:
            # JSON serialization error - log the problematic data
            logger.error("json_serialization_error",
                         error=str(e),
                         update_type=update.get("type"),
                         update_keys=list(update.keys()),
                         traceback=traceback.format_exc())

            # Try to find what's not serializable
            for key, value in update.items():
                try:
                    json.dumps(value, cls=JSONEncoder)
                except:
                    logger.error("non_serializable_field",
                                 field=key,
                                 type=type(value).__name__,
                                 value=str(value)[:100])
            raise

        except Exception as e:
            logger.error("failed_to_publish",
                         error=str(e),
                         update_type=update.get("type"),
                         traceback=traceback.format_exc())
            raise

    async def _store_session(self, session_id: str, data: Dict):
        """Store session data in Redis"""

        try:
            key = f"session:{session_id}"
            # Clean data before storing
            clean_data = self._clean_for_json(data)
            value = json.dumps(clean_data, cls=JSONEncoder)

            # Store with 1 hour TTL
            await self.redis_client.setex(key, 3600, value)
            logger.debug("stored_session", session_id=session_id)

        except Exception as e:
            logger.error("failed_to_store_session",
                         error=str(e),
                         session_id=session_id,
                         traceback=traceback.format_exc())

    def _clean_for_json(self, obj: Any) -> Any:
        """Recursively clean object for JSON serialization"""

        if obj is None:
            return None
        elif isinstance(obj, (str, int, float, bool)):
            return obj
        elif isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        elif isinstance(obj, bytes):
            return obj.decode('utf-8', errors='ignore')
        elif isinstance(obj, dict):
            return {k: self._clean_for_json(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [self._clean_for_json(item) for item in obj]
        else:
            # For unknown types, convert to string
            return str(obj)

    def _format_result_message(self, result: Dict) -> str:
        """Format result message for Slack"""

        try:
            rows = result.get("rows_count", 0)
            time = result.get("execution_time", 0)
            cost = result.get("estimated_cost", result.get("cost_usd", 0))
            cache = "‚úì Cache hit" if result.get("cache_hit") else ""

            parts = [
                f"‚úÖ Query completed successfully",
                f"‚Ä¢ Returned {rows:,} rows in {time:.1f}s" if isinstance(rows,
                                                                         (int, float)) else f"‚Ä¢ Returned {rows} rows",
                f"‚Ä¢ Cost: ${cost:.4f}" if cost else ""
            ]

            if cache:
                parts.append(f"‚Ä¢ {cache}")

            # Filter out empty parts
            parts = [p for p in parts if p]

            return "\n".join(parts)

        except Exception as e:
            logger.error("failed_to_format_result",
                         error=str(e),
                         result_keys=list(result.keys()) if result else None)
            return "‚úÖ Query completed (see details below)"

    # –û–ë–ù–û–í–õ–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
    def _format_result_blocks(self, report: Dict[str, Any]) -> list:
        """Format result as Slack blocks"""

        blocks = []

        # Summary section —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        rows_count = report.get("rows_count", 0)
        bytes_gb = report.get("bytes_processed_gb", 0)
        execution_time_ms = report.get("execution_time_ms", 0)
        cost = report.get("estimated_cost", 0)
        cache_hit = report.get("cache_hit", False)

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        metrics_text = [f"*‚úÖ Query Completed - {rows_count:,} rows*"]

        sub_metrics = []
        if execution_time_ms:
            sub_metrics.append(f"‚è± {execution_time_ms:.0f}ms")
        if bytes_gb > 0:
            sub_metrics.append(f"üíæ {bytes_gb:.2f}GB")
        if cost > 0:
            sub_metrics.append(f"üí∞ ${cost:.4f}")
        if cache_hit:
            sub_metrics.append("üöÄ Cached")

        if sub_metrics:
            metrics_text.append(" | ".join(sub_metrics))

        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "\n".join(metrics_text)
            }
        })

        # Data preview - –∏—Å–ø–æ–ª—å–∑—É–µ–º results –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ preview
        data_to_show = report.get("results", []) or report.get("preview", [])

        if data_to_show and rows_count > 0:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º preview –¥–ª—è Slack
            preview_rows = 10
            result_text = f"*Data Preview (first {min(preview_rows, len(data_to_show))} rows):*\n```\n"

            if len(data_to_show) > 0:
                # –ü–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
                headers = list(data_to_show[0].keys())

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                max_cols = 5
                if len(headers) > max_cols:
                    headers = headers[:max_cols]
                    cols_truncated = True
                else:
                    cols_truncated = False

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
                header_row = " | ".join(str(h)[:15] for h in headers)
                result_text += header_row + "\n"
                result_text += "-" * min(60, len(header_row)) + "\n"

                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö
                for i, row in enumerate(data_to_show[:preview_rows]):
                    values = []
                    for h in headers:
                        val = str(row.get(h, ""))
                        if len(val) > 15:
                            val = val[:12] + "..."
                        values.append(val)
                    result_text += " | ".join(values) + "\n"

                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Å–µ—á–µ–Ω–∏–∏
                if rows_count > preview_rows:
                    result_text += f"\n... +{rows_count - preview_rows} more rows"
                if cols_truncated:
                    result_text += f"\n... showing {max_cols} of {len(list(data_to_show[0].keys()))} columns"

            result_text += "```"

            # –î–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫ —Å –¥–∞–Ω–Ω—ã–º–∏ –µ—Å–ª–∏ –æ–Ω –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç Slack
            if len(result_text) < 2900:
                blocks.append({
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": result_text
                    }
                })

        # –°—Å—ã–ª–∫–∞ –Ω–∞ BigQuery
        table_link = report.get("table_link")
        if table_link:
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"üìä <{table_link}|View full results in BigQuery>"
                }
            })

        # SQL –∑–∞–ø—Ä–æ—Å (–∫–æ–º–ø–∞–∫—Ç–Ω–æ)
        sql = report.get("sql")
        if sql:
            sql_preview = sql.replace('\n', ' ')[:150]
            if len(sql) > 150:
                sql_preview += "..."
            blocks.append({
                "type": "context",
                "elements": [
                    {
                        "type": "mrkdwn",
                        "text": f"Query: `{sql_preview}`"
                    }
                ]
            })

        return blocks

    def _format_confirmation_blocks(self, dry_run_result: Dict[str, Any]) -> list:
        """Format confirmation request as Slack blocks"""

        blocks = []

        # Warning header
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "‚ö†Ô∏è *Large Query Detected*"
            }
        })

        # Details
        gb = dry_run_result.get('total_bytes_billed', 0) / (1024 ** 3)
        cost = dry_run_result.get('estimated_cost', 0)

        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": (
                    f"This query will process *{gb:.2f} GB* of data\n"
                    f"Estimated cost: *${cost:.2f}*\n\n"
                    "Do you want to proceed?"
                )
            }
        })

        # Show SQL preview if available
        if dry_run_result.get("sql"):
            sql_preview = dry_run_result["sql"][:500]
            if len(dry_run_result["sql"]) > 500:
                sql_preview += "..."

            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"```sql\n{sql_preview}\n```"
                }
            })

        # Action buttons
        blocks.append({
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "‚úÖ Proceed"
                    },
                    "style": "primary",
                    "action_id": "confirm_query"
                },
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "‚ùå Cancel"
                    },
                    "style": "danger",
                    "action_id": "cancel_query"
                }
            ]
        })

        return blocks

    def _format_error_blocks(self, error: str, details: Optional[str] = None) -> list:
        """Format error message as Slack blocks"""

        blocks = [
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"‚ùå *Query Failed*\n{error}"
                }
            }
        ]

        if details:
            blocks.append({
                "type": "context",
                "elements": [
                    {
                        "type": "mrkdwn",
                        "text": f"Details: {details[:200]}"  # Limit details length
                    }
                ]
            })

        # Add retry button
        blocks.append({
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": "üîÑ Retry"
                    },
                    "action_id": "retry_query"
                }
            ]
        })

        return blocks

    def _format_preview(self, rows: list, max_rows: int = 10) -> str:
        """Format preview data as table"""

        if not rows:
            return "No data"

        # Get sample rows
        sample = rows[:max_rows]

        # Get column names
        columns = list(sample[0].keys()) if sample else []

        if not columns:
            return "No columns"

        # Limit columns for display
        max_cols = 5
        if len(columns) > max_cols:
            columns = columns[:max_cols]
            truncated = True
        else:
            truncated = False

        # Calculate column widths (max 20 chars per column)
        widths = {}
        for col in columns:
            widths[col] = min(
                20,
                max(
                    len(str(col)),
                    max(len(str(row.get(col, ""))[:20]) for row in sample)
                )
            )

        # Format header
        header = " | ".join(
            str(col)[:widths[col]].ljust(widths[col])
            for col in columns
        )
        separator = "-+-".join("-" * widths[col] for col in columns)

        # Format rows
        formatted_rows = []
        for row in sample:
            formatted_row = " | ".join(
                str(row.get(col, ""))[:widths[col]].ljust(widths[col])
                for col in columns
            )
            formatted_rows.append(formatted_row)

        # Combine
        result = [header, separator] + formatted_rows

        # Add notes about truncation
        notes = []
        if len(rows) > max_rows:
            notes.append(f"... {len(rows) - max_rows} more rows")
        if truncated:
            notes.append(f"... {len(list(sample[0].keys())) - max_cols} more columns")

        if notes:
            result.append(" | ".join(notes))

        return "\n".join(result)

    def _get_bq_console_url(self, table_ref: str) -> str:
        """Get BigQuery console URL for table"""

        try:
            # Handle different formats: project.dataset.table or `project.dataset.table`
            table_ref = table_ref.replace("`", "")
            parts = table_ref.split(".")

            if len(parts) == 3:
                project, dataset, table = parts
                return (
                    f"https://console.cloud.google.com/bigquery"
                    f"?project={project}"
                    f"&ws=!1m5!1m4!4m3!1s{project}!2s{dataset}!3s{table}"
                )
            else:
                # Fallback to search
                return f"https://console.cloud.google.com/bigquery?q={table_ref}"

        except Exception as e:
            logger.error("failed_to_format_bq_url", error=str(e), table_ref=table_ref)
            return "https://console.cloud.google.com/bigquery"